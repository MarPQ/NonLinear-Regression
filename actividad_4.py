# -*- coding: utf-8 -*-
"""Actividad_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xt0ZkbFGVIEBfPJqR-1oEd6yiXhRo3Vj

Inicial
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import  train_test_split

#Obteniendo los datos del dataframe
df = pd.read_csv('df_regresion_nolineal_temp.cvs')
#print(df)

#x = np.asanyarray(df[['x']])
#y = np.asanyarray(df[['y']])

x = np.asanyarray(df[['time']])
y = np.asanyarray(df[['temp']])

"""Arbol de decisiones"""

from sklearn.tree import DecisionTreeRegressor

#Seleccionamos los datos de entrenamiento y generalizacion
x_train, x_test, y_train, y_test = train_test_split(x,y)

#Modelo

model = Pipeline([('S',StandardScaler()),('R',DecisionTreeRegressor(max_depth = 6))]) 

model.fit(x_train,y_train)

print('Train Score = ', model.score(x_train, y_train))
print('Test Score = ', model.score(x_test, y_test))

#Prediccion

x_plot = np.linspace(x.min(),x.max(),50).reshape(-1,1)
y_plot = model.predict(x_plot)

#Graficando
plt.figure()
plt.grid()
plt.title('Regresion No Lineal')
plt.xlabel('X')
plt.ylabel('Y')

plt.plot(x_train, y_train, 'bo')
plt.plot(x_test, y_test, 'ro')
plt.plot(x_plot, y_plot, 'k-', lw = 2)
plt.legend(['Dato de entrenamiento','Dato de generalizacion','Predicción'])

plt.show()

"""K vecinos mas cercanos"""

from sklearn.neighbors import KNeighborsRegressor

#Seleccionamos los datos de entrenamiento y generalizacion
x_train, x_test, y_train, y_test = train_test_split(x,y)

#Modelo

model = Pipeline([('S',StandardScaler()),('R',KNeighborsRegressor(n_neighbors = 12))])

model.fit(x_train,y_train)

print('Train Score = ', model.score(x_train, y_train))
print('Test Score = ', model.score(x_test, y_test))

#Prediccion

x_plot = np.linspace(x.min(),x.max(),50).reshape(-1,1)
y_plot = model.predict(x_plot)

#Graficando
plt.figure()
plt.grid()
plt.title('Regresion No Lineal')
plt.xlabel('X')
plt.ylabel('Y')

plt.plot(x_train, y_train, 'bo')
plt.plot(x_test, y_test, 'ro')
plt.plot(x_plot, y_plot, 'k-', lw = 2)
plt.legend(['Dato de entrenamiento','Dato de generalizacion','Predicción'])

plt.show()

"""Maquina de soporte vectorial (SVR)"""

from sklearn.svm import SVR

#Seleccionamos los datos de entrenamiento y generalizacion
x_train, x_test, y_train, y_test = train_test_split(x,y)

#Modelo

model = Pipeline([('S',StandardScaler()),('R',SVR(epsilon = 0.1, C = 50, kernel = 'rbf'))])

model.fit(x_train,y_train.ravel())

print('Train Score = ', model.score(x_train, y_train))
print('Test Score = ', model.score(x_test, y_test))

#Prediccion

x_plot = np.linspace(x.min(),x.max(),50).reshape(-1,1)
y_plot = model.predict(x_plot)

#Graficando
plt.figure()
plt.grid()
plt.title('Regresion No Lineal')
plt.xlabel('X')
plt.ylabel('Y')

plt.plot(x_train, y_train, 'bo')
plt.plot(x_test, y_test, 'ro')
plt.plot(x_plot, y_plot, 'k-', lw = 2)
plt.legend(['Dato de entrenamiento','Dato de generalizacion','Predicción'])

plt.show()

"""Modelo kernel Ridge"""

from sklearn.kernel_ridge import KernelRidge

#Seleccionamos los datos de entrenamiento y generalizacion
x_train, x_test, y_train, y_test = train_test_split(x,y)

#Modelo

model = Pipeline([('S',StandardScaler()),('R',KernelRidge(alpha = 0.01 , kernel = 'rbf'))])

model.fit(x_train,y_train.ravel())

print('Train Score = ', model.score(x_train, y_train))
print('Test Score = ', model.score(x_test, y_test))

#Prediccion

x_plot = np.linspace(x.min(),x.max(),50).reshape(-1,1)
y_plot = model.predict(x_plot)

#Graficando
plt.figure()
plt.grid()
plt.title('Regresion No Lineal')
plt.xlabel('X')
plt.ylabel('Y')

plt.plot(x_train, y_train, 'bo')
plt.plot(x_test, y_test, 'ro')
plt.plot(x_plot, y_plot, 'k-', lw = 2)
plt.legend(['Dato de entrenamiento','Dato de generalizacion','Predicción'])

plt.show()

"""Perceptron Multicapa"""

from sklearn.neural_network import MLPRegressor

#Seleccionamos los datos de entrenamiento y generalizacion
x_train, x_test, y_train, y_test = train_test_split(x,y)

#Modelo

model = Pipeline([('S',StandardScaler()),('R',MLPRegressor(hidden_layer_sizes=(100,50),
        solver = 'adam', activation = 'relu', batch_size = 10, max_iter = 500, alpha = 0.01))])

model.fit(x_train,y_train.ravel())

print('Train Score = ', model.score(x_train, y_train))
print('Test Score = ', model.score(x_test, y_test))

#Prediccion

x_plot = np.linspace(x.min(),x.max(),50).reshape(-1,1)
y_plot = model.predict(x_plot)

#Graficando
plt.figure()
plt.grid()
plt.title('Regresion No Lineal')
plt.xlabel('X')
plt.ylabel('Y')

plt.plot(x_train, y_train, 'bo')
plt.plot(x_test, y_test, 'ro')
plt.plot(x_plot, y_plot, 'k-', lw = 2)
plt.legend(['Dato de entrenamiento','Dato de generalizacion','Predicción'])

plt.show()